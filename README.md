**Machine Learning Basics**

A couple of university projects have equipped me with a deeper understanding of specific concepts and their practical implementation.

Projects include:
1. Linear Regression
2. Logistic Regression

**What I Learnt**
- Model fitting and parameter estimation: Techniques for fitting a regression model to data and estimating the coefficients or parameters that define the relationship between independent and dependent variables.
- Gradient descent optimization: The iterative optimization algorithm used to minimize the loss function and find the optimal parameters by adjusting them in the direction of the steepest descent.
- Feature selection: Methods for selecting relevant features or variables that contribute the most to the predictive performance of the regression model, while discarding irrelevant or redundant ones.
- Regularization techniques: Strategies such as L1 (Lasso) and L2 (Ridge) regularization to prevent overfitting by penalizing large coefficients, thereby promoting simpler models with better generalization ability.
- Evaluation metrics: Metrics such as mean squared error (MSE) for linear regression and metrics like accuracy, precision, recall, and F1 score for logistic regression, used to assess the performance of the model on unseen data and compare different models.
